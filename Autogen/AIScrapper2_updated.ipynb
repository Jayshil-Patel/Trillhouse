{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTZJtjPnWHMb",
        "outputId": "d50c73df-f72b-46e0-bdbc-697335909384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.2.10-py3-none-any.whl (164 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/164.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m163.8/164.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen) (5.6.3)\n",
            "Collecting docker (from pyautogen)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flaml (from pyautogen)\n",
            "  Downloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=1.3 (from pyautogen)\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.10.14)\n",
            "Collecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai>=1.3->pyautogen)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: packaging>=14.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (23.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.0.7)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.10/dist-packages (from flaml->pyautogen) (1.23.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
            "Installing collected packages: typing-extensions, python-dotenv, h11, flaml, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed docker-7.0.0 flaml-2.1.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.11.1 pyautogen-0.2.10 python-dotenv-1.0.1 tiktoken-0.5.2 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install pyautogen\n",
        "import autogen\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "API_key = userdata.get('OAI_config')"
      ],
      "metadata": {
        "id": "GzaSSNHsf3Yt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_list = [\n",
        "    {\n",
        "        'model': 'gpt-4',\n",
        "        'api_key': API_key,\n",
        "    }\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "p6XW0dlzWKZ2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config={\n",
        "    \"seed\": 50,                     # for caching and reproducibility\n",
        "    \"config_list\": config_list,     # which models to use\n",
        "    \"temperature\": 0,               # for sampling\n",
        "}\n",
        "\n",
        "# create an AssistantAgent instance named \"assistant\"\n",
        "agent_assistant = autogen.AssistantAgent(\n",
        "    name=\"agent_assistant\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "# create a UserProxyAgent that acts on the humans behalf\n",
        "agent_proxy = autogen.UserProxyAgent(\n",
        "    name=\"agent_proxy\",\n",
        "    human_input_mode=\"NEVER\",           # NEVER, TERMINATE, or ALWAYS\n",
        "                                            # TERMINATE - human input needed when assistant sends TERMINATE\n",
        "    max_consecutive_auto_reply=10,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    code_execution_config={\n",
        "        \"work_dir\": \"agent_output\",     # path for file output of program\n",
        "        \"use_docker\": False,            # True or image name like \"python:3\" to use docker image\n",
        "    },\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"\"\"Reply TERMINATE if the task has been solved at full satisfaction.\n",
        "                      Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\n",
        ")\n",
        "\n",
        "agent_proxy.initiate_chat(\n",
        "    agent_assistant,\n",
        "    message=\"\"\"I'd like for you to create a python script that meets the following requirements:\n",
        "    - uses the beautifulsoup python package\n",
        "    - searches https://www.amazon.ca/LG-24MP40A-C-FreeSync-OnScreen-Charcoal/dp/B0B273TFXW/ref=sr_1_5?crid=XY26YA6IVWGL&keywords=monitor&qid=1707062618&sprefix=monitor%2Caps%2C103&sr=8-5&th=1\n",
        "    - finds the price\n",
        "    - prints that result to the screen\n",
        "    \"\"\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEIeV0aKWRJ3",
        "outputId": "11a54809-a52f-44c7-8a37-ca41ed025811"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent_proxy (to agent_assistant):\n",
            "\n",
            "I'd like for you to create a python script that meets the following requirements:\n",
            "    - uses the beautifulsoup python package\n",
            "    - searches https://www.amazon.ca/LG-24MP40A-C-FreeSync-OnScreen-Charcoal/dp/B0B273TFXW/ref=sr_1_5?crid=XY26YA6IVWGL&keywords=monitor&qid=1707062618&sprefix=monitor%2Caps%2C103&sr=8-5&th=1\n",
            "    - finds the price \n",
            "    - prints that result to the screen\n",
            "    \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_assistant (to agent_proxy):\n",
            "\n",
            "Sure, I can help with that. Here is a Python script that uses the BeautifulSoup package to scrape the price of the product from the provided Amazon link. \n",
            "\n",
            "Please note that web scraping is against Amazon's terms of service. This script is for educational purposes only and should not be used for commercial purposes or to scrape Amazon's website at scale.\n",
            "\n",
            "```python\n",
            "# filename: amazon_price_scraper.py\n",
            "\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "\n",
            "def get_amazon_price(url):\n",
            "    headers = {\n",
            "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
            "    response = requests.get(url, headers=headers)\n",
            "\n",
            "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
            "    price = soup.find(\"span\", attrs={'class':'a-offscreen'}).string\n",
            "\n",
            "    return price\n",
            "\n",
            "url = 'https://www.amazon.ca/LG-24MP40A-C-FreeSync-OnScreen-Charcoal/dp/B0B273TFXW/ref=sr_1_5?crid=XY26YA6IVWGL&keywords=monitor&qid=1707062618&sprefix=monitor%2Caps%2C103&sr=8-5&th=1'\n",
            "price = get_amazon_price(url)\n",
            "print(price)\n",
            "```\n",
            "\n",
            "You can run this script by saving it to a file named `amazon_price_scraper.py` and then running `python amazon_price_scraper.py` in your terminal.\n",
            "\n",
            "Please note that the script might not work if Amazon changes the structure of their website or if they block the IP address from which the requests are being made.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "agent_proxy (to agent_assistant):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "$108.00\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_assistant (to agent_proxy):\n",
            "\n",
            "Great! The script worked as expected and successfully scraped the price of the product from the Amazon page. The price of the product at the moment is $108.00. Please note that this price is subject to change as it is controlled by Amazon.\n",
            "\n",
            "Remember, this script should be used responsibly and in accordance with Amazon's terms of service.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}